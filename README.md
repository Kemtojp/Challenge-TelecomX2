# ğŸ“Š Challenge Telecom X â€“ Parte 2  
**PredicciÃ³n de CancelaciÃ³n de Clientes (Churn) â€“ Telecom LATAM**  

Este proyecto desarrolla modelos de *Machine Learning* para predecir quÃ© clientes tienen mayor probabilidad de cancelar sus servicios en una empresa de telecomunicaciones.  
El objetivo principal es **identificar patrones de cancelaciÃ³n** para diseÃ±ar estrategias de retenciÃ³n mÃ¡s efectivas.  

---

## ğŸ¯ Objetivos del Proyecto
- Preparar y preprocesar los datos de clientes para modelado predictivo.  
- Analizar la distribuciÃ³n de clientes que cancelan (*Churn*) vs. los que permanecen activos.  
- Entrenar y evaluar modelos de clasificaciÃ³n para predecir *churn*.  
- Interpretar la importancia de variables y su influencia en la cancelaciÃ³n.  
- Proponer **estrategias de retenciÃ³n basadas en datos**.  

---

## ğŸ“‚ Estructura del Proyecto

Challenge_TelecomX2/

â”‚â”€â”€ datos_tratados.csv # Datos tratados en formato CSV

â”‚â”€â”€ Challenge_TelecomX2.ipynb # Cuaderno principal de anÃ¡lisis

â”‚â”€â”€ README.md # Este archivo

---

## âš™ï¸ PreparaciÃ³n de los Datos
1. **ClasificaciÃ³n de variables**:  
   - *NumÃ©ricas*: tenure, MonthlyCharges, TotalCharges.  
   - *CategÃ³ricas*: Contract, PaymentMethod, InternetService, etc.  

2. **Preprocesamiento aplicado**:  
   - ExpansiÃ³n de columnas anidadas (customer, phone, internet, account).  
   - EliminaciÃ³n de columnas irrelevantes (customerID).  
   - Tratamiento de valores faltantes.  
   - CodificaciÃ³n de variables categÃ³ricas con **One-Hot Encoding**.  
   - NormalizaciÃ³n de variables numÃ©ricas con **StandardScaler** (para regresiÃ³n logÃ­stica).  
   - Balanceo de clases con **RandomUnderSampler**.  

3. **DivisiÃ³n en conjuntos**:  
   - Entrenamiento: 80%  
   - Prueba: 20%  

---

## ğŸ” AnÃ¡lisis Exploratorio de Datos (EDA)
Durante el EDA se identificaron los siguientes patrones:  
- Clientes con **contratos cortos (Month-to-month)** presentan mayor cancelaciÃ³n.  
- **Tenure bajo** es el predictor mÃ¡s fuerte de churn.  
- Clientes con **facturaciÃ³n electrÃ³nica (PaperlessBilling)** tienden a cancelar mÃ¡s.  
- **Cargos mensuales bajos** se relacionan con mayor probabilidad de cancelaciÃ³n.  

ğŸ“Š **Ejemplos de grÃ¡ficos incluidos en el notebook**:  
- Boxplots de gastos mensuales y totales vs. churn.  
- Scatter plots de tenure Ã— churn.  
- Matrices de correlaciÃ³n entre variables.  
- Matrices de confusiÃ³n de los modelos.  

---

## ğŸ¤– Modelado Predictivo
Se entrenaron y evaluaron dos modelos principales:  

- **RegresiÃ³n LogÃ­stica**  
  - Accuracy: ~0.74  
  - F1-score: ~0.74  
  - LimitaciÃ³n: mÃ¡s falsos negativos al predecir clientes que cancelan.  

- **Random Forest**  
  - Accuracy: ~0.77  
  - F1-score: ~0.78  
  - Mejor desempeÃ±o en detecciÃ³n de churners.  

ğŸ“Œ **Importancia de variables clave**:  
- Contract (duraciÃ³n de contrato).  
- Tenure (tiempo de permanencia).  
- MonthlyCharges y TotalCharges.  
- PaperlessBilling.  

---

## ğŸ“ˆ Conclusiones e Insights
- **Random Forest** superÃ³ a la regresiÃ³n logÃ­stica en mÃ©tricas de rendimiento.  
- Los factores mÃ¡s crÃ­ticos para la cancelaciÃ³n son:  
  1. Contratos cortos.  
  2. Bajo tiempo de permanencia.  
  3. FacturaciÃ³n electrÃ³nica.  
  4. Gastos mensuales bajos.  

ğŸ“¢ **Recomendaciones para la empresa**:  
- Incentivar renovaciÃ³n de contratos cortos.  
- Programas de fidelizaciÃ³n para clientes nuevos.  
- Mejorar la experiencia de PaperlessBilling.  
- Monitoreo de clientes con bajo gasto mensual y tenure bajo.  

---

## ğŸ› ï¸ TecnologÃ­as Usadas
- **Manejo de datos**: pandas, numpy, json, ast.
- **VisualizaciÃ³n**: matplotlib, seaborn.
- **Preprocesamiento y Modelado**:
  - OneHotEncoder, StandardScaler, ColumnTransformer, Pipeline (scikit-learn).
  - **Modelos**: LogisticRegression, RandomForestClassifier.
  - **DivisiÃ³n de datos**: train_test_split.
  - **Balanceo de clases**: RandomUnderSampler (imblearn).
- **MÃ©tricas y evaluaciÃ³n**: classification_report, confusion_matrix, ConfusionMatrixDisplay. 

---

## ğŸš€ EjecuciÃ³n del Proyecto
1. Clonar el repositorio o descargar el archivo `.ipynb`.  
2. Abrir el cuaderno en Google Colab o Jupyter Notebook.  
3. Instalar dependencias:  

```bash
pip install pandas numpy matplotlib seaborn scikit-learn imbalanced-learn
Cargar los datos (ubicados en datos_tratados.csv).

Ejecutar las celdas en orden para reproducir el anÃ¡lisis completo.
```

---

## ğŸ‘¤ Autor

- **Juan Velasquez**
- [Perfil de GitHub] (https://github.com/Kemtojp)
- [Perfil de LinkedIn] (https://www.linkedin.com/in/juan-velasquez-becerra/)
